{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 實作 - 寫入檔案\n",
    "# 萃取字詞的四大方法\n",
    "# 首先要先確定有 [字典] 和 [停用詞] 的txt檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\Users\\BigData\\dict.big.tra.txt ...\n",
      "DEBUG:jieba:Building prefix dict from C:\\Users\\BigData\\dict.big.tra.txt ...\n",
      "Loading model from cache c:\\users\\bigdata\\appdata\\local\\temp\\jieba.ud8ec30fabaf60e161f06b3552aab2f0e.cache\n",
      "DEBUG:jieba:Loading model from cache c:\\users\\bigdata\\appdata\\local\\temp\\jieba.ud8ec30fabaf60e161f06b3552aab2f0e.cache\n",
      "Loading model cost 0.263 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.263 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import jieba.posseg as pseg  \n",
    "jieba.set_dictionary('dict.big.tra.txt')  #預設字典\n",
    "jieba.load_userdict('dict_twstd_tfidf.txt')  #中文分詞詞庫(TFIDF)\n",
    "jieba.load_userdict('dict_ntusd_pos.txt') #NTUSD_負向\n",
    "jieba.load_userdict('dict_ntusd_nag.txt') #NTUSD_正向\n",
    "jieba.load_userdict('dict_twedu_dict.txt') #教育部《重編國語辭典 修訂本》\n",
    "\n",
    "\n",
    "#jieba.load_userdict('dict_20160111_NotReallyUseful.txt')  \n",
    "#中文分詞詞庫(TFIDF) + 百度分詞詞庫 + 69萬中文大辭典 + 中文热门词库(155073) \n",
    "#不是很好用，可備著使用\n",
    "\n",
    "\n",
    "jieba.analyse.set_stop_words(\"stopwords_1227.txt\") #停用詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 單一景點使用[Jieba TFIDF]的方法\n",
    "def jiebastat(attraction,rankNum,filename):\n",
    "#轉換象山資料,並切詞,並使用JIEBA內建的tfidf統計排名\n",
    "    f = open(attraction,'r')  #讀取檔案\n",
    "    f1 = f.read()  #接住\n",
    "    f2 = ''.join(f1.split())  #把空白全去掉\n",
    "    #print f2\n",
    "    words=jieba.cut(f2)  #斷詞\n",
    "    n = ' '.join(words)  #把斷詞結果用空白隔開\n",
    "    n1 = n.encode('utf-8')  #編碼\n",
    "    f.close()\n",
    "\n",
    "\n",
    "    temp = []\n",
    "    temp2 =[]\n",
    "    x = jieba.analyse.extract_tags(n1, topK=rankNum, withWeight=True)\n",
    "    for u in x:\n",
    "        #print u[0],\"\\t\",u[1]\n",
    "        temp.append(u[0].encode('utf-8'))  #存詞彙\n",
    "        temp2.append(u[1])  #存權重\n",
    "        \n",
    "    fid = open(filename,'a')\n",
    "    #統計字頻\n",
    "    dic={}\n",
    "    for w in n1.split(' '):\n",
    "        if w not in dic:\n",
    "            dic[w] = 1\n",
    "        else:\n",
    "            dic[w] = dic[w] + 1\n",
    "    import operator\n",
    "    words_freq = sorted(dic.iteritems(),key=operator.itemgetter(1),reverse=True)\n",
    "    #print attraction#,\"\\n總詞量：\",len(words_freq)\n",
    "    fid.write(attraction+',')\n",
    "    fid.write(\"\\n\")\n",
    "    \n",
    "\n",
    "    #根據Jieba tf-idf去看字頻排名\n",
    "    #print \"=========字頻統計(根據jieba TFIDF)=========\"\n",
    "    #print \"排名\",\"\\t\",\"總排\",\"\\t\",\"詞彙\",\"\\t\",\"出現次數\",\"  \",\"權重\",\"\\t\\t\\t\",\"比率\"\n",
    "    #print \"- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\"\n",
    "    num = 0\n",
    "    num3 = -1\n",
    "    for ele in words_freq:\n",
    "        num += 1\n",
    "        if ele[0] in temp:\n",
    "            num3 += 1\n",
    "            #print num3+1,\"\\t\",num,\"\\t\",ele[0],\"\\t\",ele[1],\"\\t\",\"   \",temp2[num3],\\\n",
    "            #\"\\t\",float(int(( float(ele[1]) / float(len(words_freq)) ) *10000))/100,'%'\n",
    "            #print ele[0]\n",
    "            fid.write(ele[0]+',\\n')\n",
    "    fid.write(\"\\n\")\n",
    "    fid.close()\n",
    "# 比對多個景點[Jieba TFIDF]的方法\n",
    "def mutijiebastat(date,attrlist,RankNum):\n",
    "    filename = 'JiebaTfidf-'+str(RankNum)+'-'+date+'.txt'    \n",
    "    for i in range(0,len(attrlist)):\n",
    "        jiebastat(attrlist[i],RankNum,filename)\n",
    "        #print '\\n'\n",
    "########       \n",
    "# 方法二：計算Scikit-Learn的TFIDF值\n",
    "########\n",
    "def wordsToList(attfile):\n",
    "    f = open(attfile,'r')\n",
    "    f1 = f.read()\n",
    "    f2 = ''.join(f1.split())\n",
    "    #print f2\n",
    "    words=jieba.cut(f2)\n",
    "    n = ' '.join(words)\n",
    "    n1 = n.encode('utf-8')\n",
    "    return n1\n",
    "    f.close()\n",
    "\n",
    "def stopWordsList(stopwordfile):\n",
    "    li = []\n",
    "    fid =  open(stopwordfile,'r')\n",
    "    for line in fid:\n",
    "        li.append(line.strip().decode('utf-8'))#要解開utf-8,才能成功給scikitlearn用\n",
    "    fid.close()\n",
    "    return li\n",
    "\n",
    "def CompareTFIDF(date,listInput,stopWordsFile,rankNum):\n",
    "    from sklearn import feature_extraction  \n",
    "    from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    filename = 'SciTfidf-'+str(rankNum)+'-'+date+'.txt'\n",
    "    fid = open(filename,'a')\n",
    "    #創造一個空矩陣\n",
    "    corpus = []\n",
    "    \n",
    "    #把傳入的List依序讀出，使用方法把這些東西全都讀出來\n",
    "    for each in range(0,len(listInput)):\n",
    "        corpus.append(wordsToList(listInput[each]))\n",
    "\n",
    "    vectorizer=CountVectorizer(analyzer='word',stop_words=stopWordsList(stopWordsFile))  #該類會將文本中的詞語轉換為詞頻矩陣，矩陣元素a[i][j] 表示j詞在i類文本下的詞頻  \n",
    "    x = vectorizer.fit_transform(corpus)  #將文本轉為詞頻矩陣 \n",
    "    transformer=TfidfTransformer()  #該類會統計每個詞語的tf-idf權值 \n",
    "    tfidf=transformer.fit_transform(x)  #計算tf-idf\n",
    "    word=vectorizer.get_feature_names()  #獲取詞袋模型中的所有詞語\n",
    "    weight=tfidf.toarray()   #將tf-idf矩陣抽取出來，元素a[i][j]表示j詞在i類文本中的tf-idf權重  \n",
    "\n",
    "    #print '-------以下輸出各景點中TFIDF值最高的幾個詞語------\\n'\n",
    "    \n",
    "    #打印每類文本的tf-idf詞語權重，第一個for遍歷所有文本，第二個for便利某一類文本下的詞語權重\n",
    "    import operator\n",
    "    for i in range(len(weight)):\n",
    "        #print listInput[i]\n",
    "        fid.write(listInput[i]+',')\n",
    "        fid.write('\\n')\n",
    "        #print listInput[i],\"\\n------文章內詞語tf-idf權重------\" \n",
    "        #print \"排名\",'\\t',\"詞語\",\"\\t\",\"權重\"\n",
    "        #print \"- - - - - - - - - - - - - - - -\"\n",
    "        dic = {}\n",
    "        for j in range(len(word)):  \n",
    "            dic[word[j]] = weight[i][j]\n",
    "        words_freq = sorted(dic.iteritems(),key=operator.itemgetter(1),reverse=True)\n",
    "        num2 = 0\n",
    "        for ele in words_freq[0:rankNum]:\n",
    "            num2 += 1\n",
    "            #print num2,\"\\t\",ele[0],\"\\t\",ele[1]\n",
    "            #print ele[0]\n",
    "            fid.write(ele[0].encode('utf-8')+',')\n",
    "            fid.write(\"\\n\")\n",
    "        #print '\\n'\n",
    "        fid.write('\\n')\n",
    "    fid.close()\n",
    "########       \n",
    "# 方法三：計算字頻 - 文章斷詞的原始字頻\n",
    "########\n",
    "def jiebafrestat(attraction,rankNum,filename):\n",
    "#轉換象山資料,並切詞,並使用JIEBA內建的tfidf統計排名\n",
    "    f = open(attraction,'r')  #讀取檔案\n",
    "    f1 = f.read()  #接住\n",
    "    f2 = ''.join(f1.split())  #把空白全去掉\n",
    "    #print f2\n",
    "    words=jieba.cut(f2)  #斷詞\n",
    "    n = ' '.join(words)  #把斷詞結果用空白隔開\n",
    "    n1 = n.encode('utf-8')  #編碼\n",
    "    f.close()\n",
    "    \n",
    "    fid = open(filename,'a')\n",
    "    \n",
    "    #統計字頻\n",
    "    dic={}\n",
    "    for w in n1.split(' '):\n",
    "        if w not in dic:\n",
    "            dic[w] = 1\n",
    "        else:\n",
    "            dic[w] = dic[w] + 1\n",
    "    import operator\n",
    "    words_freq = sorted(dic.iteritems(),key=operator.itemgetter(1),reverse=True)\n",
    "    #print attraction#,\"\\n總詞量：\",len(words_freq)\n",
    "    fid.write(attraction+',')\n",
    "    fid.write('\\n')\n",
    "    #列出原始字頻排名\n",
    "    #print \"==========字頻統計==========\"\n",
    "    #print \"排名\",\"\\t\",\"詞彙\",\"\\t\",\"字頻\"\n",
    "    #print \"- - - - - - - - - - - - - - \"\n",
    "    num2 = 0\n",
    "    for ele in words_freq[0:rankNum]:\n",
    "        num2 += 1\n",
    "        #print num2,\"\\t\",ele[0],\"\\t\",ele[1]\n",
    "        #print ele[0]\n",
    "        #print type(ele[0])\n",
    "        #x = ele[0].encode('utf-8')\n",
    "        fid.write(ele[0])        \n",
    "        fid.write(',\\n')\n",
    "    fid.write('\\n')\n",
    "    fid.close()\n",
    "#        if num2 % 10 == 0:\n",
    "            #print \"- - - - - - - - - - - - - - \"\n",
    "            \n",
    "# 比對多個景點斷詞字頻的方法\n",
    "def mutifrestat(date,attrlist,RankNum):\n",
    "    filename = 'WordsFre-'+str(RankNum)+'-'+date+'.txt'  \n",
    "    for i in range(0,len(attrlist)):\n",
    "        jiebafrestat(attrlist[i],RankNum,filename)\n",
    "        #print '\\n'\n",
    "########       \n",
    "# 方法四：計算字頻 - 去除停用詞後的字頻統計\n",
    "########\n",
    "def stopWordsSet(stopwordfile):\n",
    "    li = []\n",
    "    fid =  open(stopwordfile,'r')\n",
    "    for line in fid:\n",
    "        li.append(line.strip())\n",
    "    fid.close()\n",
    "    setli = set(li)\n",
    "    return setli\n",
    "\n",
    "def jiebafrestopwords(attraction,stopwordfile,rankNum,filename):\n",
    "#轉換象山資料,並切詞,並使用JIEBA內建的tfidf統計排名\n",
    "    f = open(attraction,'r')  #讀取檔案\n",
    "    f1 = f.read()  #接住\n",
    "    f2 = ''.join(f1.split())  #把空白全去掉\n",
    "    #print f2\n",
    "    words=jieba.cut(f2)  #斷詞\n",
    "    n = ' '.join(words)  #把斷詞結果用空白隔開\n",
    "    n1 = n.encode('utf-8')  #編碼\n",
    "    f.close()\n",
    "    \n",
    "    fid = open(filename,'a')\n",
    "    \n",
    "    #統計字頻\n",
    "    dic={}\n",
    "    comparelist = stopWordsSet(stopwordfile)\n",
    "    for w in n1.split(' '):\n",
    "        if w not in comparelist:\n",
    "            if w not in dic:\n",
    "                dic[w] = 1\n",
    "            else:\n",
    "                dic[w] = dic[w] + 1\n",
    "    import operator\n",
    "    words_freq = sorted(dic.iteritems(),key=operator.itemgetter(1),reverse=True)\n",
    "    #print attraction#,\"\\n總詞量(去除停用詞後)：\",len(words_freq)\n",
    "    fid.write(attraction+',\\n')\n",
    "    #列出原始字頻排名\n",
    "    #print \"==========字頻統計==========\"\n",
    "    #print \"排名\",\"\\t\",\"詞彙\",\"\\t\",\"字頻\"\n",
    "    #print \"- - - - - - - - - - - - - - \"\n",
    "    num2 = 0\n",
    "    for ele in words_freq[0:rankNum]:\n",
    "        num2 += 1\n",
    "        #print num2,\"\\t\",ele[0],\"\\t\",ele[1]\n",
    "        #print ele[0]\n",
    "        fid.write(ele[0])\n",
    "        fid.write(',\\n')\n",
    "        #if num2 % 10 == 0:\n",
    "            #print \"- - - - - - - - - - - - - - \"\n",
    "    fid.write('\\n')\n",
    "    fid.close()        \n",
    "# 比對多個景點斷詞字頻(去停用詞後)的方法\n",
    "def mutifrestopwords(date,attrlist,stopWordsFile,RankNum):\n",
    "    filename = 'WordsFreAddStop-'+str(RankNum)+'-'+date+'.txt' \n",
    "    for i in range(0,len(attrlist)):\n",
    "        jiebafrestopwords(attrlist[i],stopWordsFile,RankNum,filename)\n",
    "        #print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 綜合比對\n",
    "使用方法：\n",
    "\n",
    "    1.新增一陣列：內含要分析景點的檔案名稱(TXT)\n",
    "    2.決定要使用的停用詞字典(TXT)\n",
    "    3.決定要顯示的排名數\n",
    "\n",
    "使用範例：\n",
    "\n",
    "    陣列 = [景點A檔,景點B檔,景點C檔]\n",
    "    \n",
    "    1.單一TFIDF\n",
    "    --def mutijiebastat(date,attrlist,RankNum)\n",
    "    mutijiebastat(日期,陣列,顯示排名數)\n",
    "    \n",
    "    2.多重TFIDF\n",
    "    --def CompareTFIDF(date,listInput,stopWordsFile,rankNum)\n",
    "    CompareTFIDF(日期,陣列,停用詞字典,顯示排名數)\n",
    "    \n",
    "    3.原始字頻統計\n",
    "    --def def mutifrestat(date,attrlist,RankNum)\n",
    "    mutifrestat(日期,陣列,顯示排名數)\n",
    "    \n",
    "    4.去停用詞後字頻統計\n",
    "    --def mutifrestopwords(date,attrlist,stopWordsFile,RankNum)\n",
    "    mutifrestopwords(日期,陣列,停用詞字典,顯示排名數)\n",
    "    \n",
    "實作：\n",
    "\n",
    "    list = ['mountain.txt','lungshanTemple.txt','maokongGondola.txt']\n",
    "    rank = 10\n",
    "    date = '20151223'\n",
    "    stpDic = 'stopwords_1222.txt'\n",
    "    \n",
    "    mutijiebastat(date,lis,rank)\n",
    "    \n",
    "    CompareTFIDF(date,lis,stpDic,rank)\n",
    "    \n",
    "    mutifrestat(date,lis,rank)\n",
    "    \n",
    "    mutifrestopwords(date,lis,stpDic,rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FourWayPK(folder,date,rank,stpDic):\n",
    "    #實作：\n",
    "    import time\n",
    "    import os\n",
    "    lis = []\n",
    "    for name in os.listdir(folder):\n",
    "        path = folder+'\\\\'+name\n",
    "        lis.append(path)\n",
    "\n",
    "    x = time.time()\n",
    "    #date = '20151223'\n",
    "    #lis = ['mountain.txt','lungshanTemple.txt','maokongGondola.txt']\n",
    "    #rank = 10\n",
    "    #stpDic = 'stopwords_1227.txt'\n",
    "\n",
    "    mutijiebastat(date,lis,rank)\n",
    "\n",
    "    CompareTFIDF(date,lis,stpDic,rank)\n",
    "\n",
    "    mutifrestat(date,lis,rank)\n",
    "\n",
    "    mutifrestopwords(date,lis,stpDic,rank)\n",
    "\n",
    "    y = time.time()\n",
    "    print 'Finish!'\n",
    "    print 'Cost ',y-x,' secs.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 綜合比對 方法\n",
    "使用說明：\n",
    "\n",
    "    FourWayPK(資料夾,日期,排名,停用詞字典)\n",
    "    \n",
    "    資料夾：[字串]。資料夾名稱，內含所有以景點為單位的TXT檔(命名要用英文)\n",
    "           EX:有一'AttrSample'的資料夾，內有30個檔，\n",
    "              每個檔都是一個單獨景點的所有評論\\遊記。\n",
    "              \n",
    "    日　期：[字串]。輸入今天日期，格式-->'YYYYMMDD'\n",
    "           EX:'20151223'\n",
    "           \n",
    "    排　名：[整數]。想要顯示各方法的前幾個排名數\n",
    "           EX:10\n",
    "           \n",
    "    停用詞：[字串]。TXT檔。內容格式需為一行一個字詞，字詞後不得有逗點\n",
    "           EX:'stopwords_1222.txt'\n",
    "\n",
    "方法結果：\n",
    "\n",
    "    會在所在的資料夾產生四個TXT檔，開頭分別為：\n",
    "    1.JiebaTfidf　　　　-->單一TFIDF\n",
    "    2.SciTfidf         -->多重TFIDF\n",
    "    3.WordsFre         -->普通字頻統計\n",
    "    4.WordsFreAddStop  -->去停用詞字頻統計\n",
    "    \n",
    "    分別是四個方法的結果，並且會依照景點排序。\n",
    "    \n",
    "    且會傳回所耗時數！\n",
    "    \n",
    "# 【注意】每次使用的＂日期＂都要設不一樣\n",
    "# 　　　　否則會在同一個檔案一直append下去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish!\n",
      "Cost  19.9559998512  secs.\n"
     ]
    }
   ],
   "source": [
    "FourWayPK('AttrSample','20151223',10,'stopwords_1227.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
