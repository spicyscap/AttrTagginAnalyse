{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python 利用Scikit-Learn套件實作TFIDF的方法\n",
    "# 首先要先確定有 [字典] 和 [停用詞] 的txt檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\Users\\BigData\\dict.big.tra.txt ...\n",
      "DEBUG:jieba:Building prefix dict from C:\\Users\\BigData\\dict.big.tra.txt ...\n",
      "Loading model from cache c:\\users\\bigdata\\appdata\\local\\temp\\jieba.ud8ec30fabaf60e161f06b3552aab2f0e.cache\n",
      "DEBUG:jieba:Loading model from cache c:\\users\\bigdata\\appdata\\local\\temp\\jieba.ud8ec30fabaf60e161f06b3552aab2f0e.cache\n",
      "Loading model cost 0.316 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.316 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import jieba.posseg as pseg  \n",
    "jieba.set_dictionary('dict.big.tra.txt')  #預設字典\n",
    "jieba.load_userdict('dict_twstd_tfidf.txt')  #中文分詞詞庫(TFIDF)\n",
    "jieba.load_userdict('dict_ntusd_pos.txt') #NTUSD_負向\n",
    "jieba.load_userdict('dict_ntusd_nag.txt') #NTUSD_正向\n",
    "jieba.load_userdict('dict_twedu_dict.txt') #教育部《重編國語辭典 修訂本》\n",
    "\n",
    "\n",
    "#jieba.load_userdict('dict_20160111_NotReallyUseful.txt')  \n",
    "#中文分詞詞庫(TFIDF) + 百度分詞詞庫 + 69萬中文大辭典 + 中文热门词库(155073) \n",
    "#不是很好用，可備著使用\n",
    "\n",
    "\n",
    "jieba.analyse.set_stop_words(\"stopwords_1227.txt\") #停用詞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 把斷詞結果存進陣列的方法\n",
    "使用說明：\n",
    "\n",
    "    wordsToList(傳入的檔名(TXT))\n",
    "\n",
    "    檔名內容不拘，只要是在講同一個景點的都可以\n",
    "    回傳會是檔案的斷詞結果，用List表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wordsToList(attfile):\n",
    "    f = open(attfile,'r')\n",
    "    f1 = f.read()\n",
    "    f2 = ''.join(f1.split())\n",
    "    #print f2\n",
    "    words=jieba.cut(f2)\n",
    "    n = ' '.join(words)\n",
    "    n1 = n.encode('utf-8')\n",
    "    return n1\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用停用詞的方法\n",
    "使用說明：\n",
    "    stopWordsList(傳入的檔名(TXT))\n",
    "    \n",
    "    傳入檔：停用詞的詞庫檔。內部格式必須為\"一行一個詞語\"( 詞語後不得有逗號 )\n",
    "    使用後會把檔案內容，回傳成一個List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stopWordsList(stopwordfile):\n",
    "    li = []\n",
    "    fid =  open(stopwordfile,'r')\n",
    "    for line in fid:\n",
    "        li.append(line.strip().decode('utf-8'))#要解開utf-8,才能成功給scikitlearn用\n",
    "    fid.close()\n",
    "    return li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List內容 比較UTF-8解開與否的結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\xe4\\xb8\\x80\\xe5\\x80\\x8b']\n",
      "[u'\\u4e00\\u500b']\n"
     ]
    }
   ],
   "source": [
    "st = ['一個']\n",
    "print st\n",
    "st2 = ['一個'.decode('utf-8')]\n",
    "print st2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 計算出不同文章間詞語TFIDF值的方法\n",
    "\n",
    "使用方法：\n",
    "\n",
    "    CompareTFIDF(listInput,stopWordsFile,rankNum)\n",
    "    \n",
    "    listInput：TXT檔，包含要傳入檔案名稱，合成的一個陣列\n",
    "               例如：['mountain.txt','lungshanTemple.txt','maokongGondola.txt']\n",
    "               或是先新增一個陣列，再用變數去接住，傳變數也可以\n",
    "               \n",
    "    stopWordsFile：TXT檔，停用詞的詞庫檔。內部格式必須為\"一行一個詞語\"( 詞語後不得有逗號 )\n",
    "    \n",
    "    rankNum：數字(整數)，表示要列出各文章的排名前幾的詞語\n",
    "    \n",
    "使用範例：\n",
    "    \n",
    "    CompareTFIDF(['mountain.txt','lungshanTemple.txt','maokongGondola.txt'],'stopwords_1222.txt',5)\n",
    "    \n",
    "    or\n",
    "    \n",
    "    list = ['mountain.txt','lungshanTemple.txt','maokongGondola.txt']\n",
    "    CompareTFIDF(list,'stopwords_1222.txt',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CompareTFIDF(listInput,stopWordsFile,rankNum):\n",
    "    from sklearn import feature_extraction  \n",
    "    from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    \n",
    "    #創造一個空矩陣\n",
    "    corpus = []\n",
    "    \n",
    "    #把傳入的List依序讀出，使用方法把這些東西全都讀出來\n",
    "    for each in range(0,len(listInput)):\n",
    "        corpus.append(wordsToList(listInput[each]))\n",
    "\n",
    "    vectorizer=CountVectorizer(analyzer='word',stop_words=stopWordsList(stopWordsFile))  #該類會將文本中的詞語轉換為詞頻矩陣，矩陣元素a[i][j] 表示j詞在i類文本下的詞頻  \n",
    "    x = vectorizer.fit_transform(corpus)  #將文本轉為詞頻矩陣 \n",
    "    transformer=TfidfTransformer()  #該類會統計每個詞語的tf-idf權值 \n",
    "    tfidf=transformer.fit_transform(x)  #計算tf-idf\n",
    "    word=vectorizer.get_feature_names()  #獲取詞袋模型中的所有詞語\n",
    "    weight=tfidf.toarray()   #將tf-idf矩陣抽取出來，元素a[i][j]表示j詞在i類文本中的tf-idf權重  \n",
    "\n",
    "    print '-------以下輸出各景點中TFIDF值最高的幾個詞語------\\n'\n",
    "    \n",
    "    #打印每類文本的tf-idf詞語權重，第一個for遍歷所有文本，第二個for便利某一類文本下的詞語權重\n",
    "    import operator\n",
    "    for i in range(len(weight)):\n",
    "        print \"------景點 \",listInput[i],\" 類文章內詞語tf-idf權重------\" \n",
    "        print \"排名\",'\\t',\"詞語\",\"\\t\",\"權重\"\n",
    "        print \"- - - - - - - - - - - - - - - -\"\n",
    "        dic = {}\n",
    "        for j in range(len(word)):  \n",
    "            dic[word[j]] = weight[i][j]\n",
    "        words_freq = sorted(dic.iteritems(),key=operator.itemgetter(1),reverse=True)\n",
    "        num2 = 0\n",
    "        for ele in words_freq[0:rankNum]:\n",
    "            num2 += 1\n",
    "            print num2,\"\\t\",ele[0],\"\\t\",ele[1]\n",
    "        print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------以下輸出各景點中TFIDF值最高的幾個詞語------\n",
      "\n",
      "------景點  mountain.txt  類文章內詞語tf-idf權重------\n",
      "排名 \t詞語 \t權重\n",
      "- - - - - - - - - - - - - - - -\n",
      "1 \t101 \t0.419783594375\n",
      "2 \t象山 \t0.348452306491\n",
      "3 \t地方 \t0.234176798515\n",
      "4 \t城市 \t0.213361083092\n",
      "5 \t大象 \t0.192095502296\n",
      "6 \t值得 \t0.168260366341\n",
      "7 \t夜景 \t0.150913936821\n",
      "\n",
      "\n",
      "------景點  lungshanTemple.txt  類文章內詞語tf-idf權重------\n",
      "排名 \t詞語 \t權重\n",
      "- - - - - - - - - - - - - - - -\n",
      "1 \t寺廟 \t0.622179753309\n",
      "2 \t龍山寺 \t0.488852121263\n",
      "3 \t地方 \t0.191127113762\n",
      "4 \t臺灣 \t0.142328701737\n",
      "5 \t夜市 \t0.127418075841\n",
      "6 \t值得 \t0.123351541506\n",
      "7 \t文化 \t0.0977461960654\n",
      "\n",
      "\n",
      "------景點  maokongGondola.txt  類文章內詞語tf-idf權重------\n",
      "排名 \t詞語 \t權重\n",
      "- - - - - - - - - - - - - - - -\n",
      "1 \t纜車 \t0.516165487179\n",
      "2 \t貢多拉 \t0.351399397095\n",
      "3 \t貓空 \t0.33188958428\n",
      "4 \t動物園 \t0.287509000335\n",
      "5 \t水晶 \t0.260060925648\n",
      "6 \t等待 \t0.125423389408\n",
      "7 \t玻璃 \t0.119634617589\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lis = ['mountain.txt','lungshanTemple.txt','maokongGondola.txt']\n",
    "CompareTFIDF(lis,'stopwords_1227.txt',7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
